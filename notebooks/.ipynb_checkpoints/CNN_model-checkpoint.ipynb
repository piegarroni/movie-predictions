{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a195db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 18:38:45.045315: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, AveragePooling2D, Dense, GlobalAveragePooling2D, SpatialDropout2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import time\n",
    "import os\n",
    "import time\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import models\n",
    "from pathlib import Path\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1f2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../../data/meta_rotten.csv')\n",
    "subtitles=pd.read_csv('../../data/movies_subtitles.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102958c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe with subtitles of every movie\n",
    "start=time.time()\n",
    "movies_ids=list(subtitles['imdb_id'].unique())\n",
    "movies_list=[]\n",
    "\n",
    "for index in movies_ids[:20]:\n",
    "    globals()['%s' % index]= subtitles.loc[subtitles['imdb_id']==index]\n",
    "    movies_list.append(globals()['%s' % index])\n",
    "    \n",
    "end=time.time()\n",
    "print(\"time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NLU model\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')  \n",
    "word_embeddings = model.transformer.wte.weight  \n",
    "position_embeddings = model.transformer.wpe.weight \n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the matrix for every movie\n",
    "start=time.time()\n",
    "remove_digits = str.maketrans('', '', digits) # object to remove numbers\n",
    "\n",
    "matrix_subtitles=[]#pd.DataFrame(movies_list, columns=[\"movie\"])\n",
    "\n",
    "for movie in movies_list:\n",
    "        \n",
    "    dimension=int(len(movie)/768)\n",
    "    low_bound=0\n",
    "    high_bound=dimension   \n",
    " \n",
    "    movie_words=[]\n",
    "    \n",
    "    # for every split of one movie's subtitle get list of words\n",
    "    for i in range(768):\n",
    "        text=[]\n",
    "        subset=movie.iloc[low_bound:high_bound]       \n",
    "        text+=subset['text'].to_string().split() # split string\n",
    "        text = [x for x in text if not (x.isdigit())]  # remove numbers (index)\n",
    "        globals()['sentences_%s' % i]=text\n",
    "        low_bound+=dimension\n",
    "        high_bound+=dimension\n",
    "        movie_words.append(globals()['sentences_%s' % i])  # append list of words to movie_words\n",
    "        \n",
    "        \n",
    "################ split for time complexity????\n",
    "    matrix=[]\n",
    "\n",
    "    # for every list of words obtain vector and append to matrix\n",
    "    for sentence in movie_words:\n",
    "        sent_vect=[]\n",
    "        for word in sentence:\n",
    "            text_index = tokenizer.encode(word,add_prefix_space=True)\n",
    "            vector = model.transformer.wte.weight[text_index,:]\n",
    "            vector=vector.detach().numpy()         \n",
    "            sent_vect.append(vector[0])\n",
    "        matrix.append(np.sum(sent_vect, axis=0) / len(sent_vect))  \n",
    "   \n",
    "    matrix_subtitles.append(np.array(matrix))\n",
    "    \n",
    "end=time.time()\n",
    "print(\"time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(matrix_subtitles))\n",
    "print(type(matrix_subtitles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db040536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f661633",
   "metadata": {},
   "outputs": [],
   "source": [
    "for matrix in matrix_subtitles:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(matrix, cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c918c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block():  \n",
    "    def __init__(self, n_layers, kernel_size=(5, 5), dropout_rate=0.2):\n",
    "        self.conv = Conv2D(n_layers, kernel_size, activation='relu', padding='same')\n",
    "        self.conv2 = Conv2D(n_layers*2, kernel_size, activation='relu', padding='same')\n",
    "        self.conv3 = Conv2D(n_layers*2, kernel_size, activation='relu', padding='same')\n",
    "        self.conv4 = Conv2D(n_layers, kernel_size, activation='relu', padding='same')      \n",
    "        self.pooling = AveragePooling2D(2)\n",
    "        self.bn = BatchNormalization()\n",
    "        self.dropout = SpatialDropout2D(dropout_rate)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pooling(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "                       \n",
    "class CNN():\n",
    "    def __init__(self):\n",
    "        self.conv_block1 = conv_block(512)\n",
    "        self.conv_block2 = conv_block(256)\n",
    "        self.conv_block3 = conv_block(128)\n",
    "        self.conv_block4 = conv_block(64)        \n",
    "        self.pool=GlobalAveragePooling2D()  \n",
    "        self.dense = Dense(3)\n",
    "        \n",
    "    def call(self, x):     \n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ed92f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mCNN\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CNN' is not defined"
     ]
    }
   ],
   "source": [
    "model=CNN()\n",
    "#model.compile(optimizer=Adam, loss=[accuracy],)\n",
    "#model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/tasks/sequence_classification for transformers classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
